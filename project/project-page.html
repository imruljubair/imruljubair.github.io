<!DOCTYPE html>
<html>
<head>
<style>
div {
    margin-top: 100px;
    margin-bottom: 100px;
    margin-left: 100px;
    margin-right: 10px;
    font-size: 80%;
    font-family:Arial;
}
</style>
</head>
<head>
  <title>Projects | Jubair</title>
</head>
<body>

<div>
  <h2>Mohammad Imrul Jubair | Projects</h2>
  <!--<h2>Project Page</h2>-->
  <p>|<a href="/index.html#projects"> back to homepage </a>|</p>
  <br>
  <br>
  <br>
    <a name="jamdani"></a>
  <h2> Intelligent Jamdani Motif Generator (2020)</h2>
  <p class="lead"> [Ongoing] </p>
  <p class="lead">
  <ul>
    In this project, we are working on developing a technique based on Generative Adversarial Network that can learn to generate entirely new Jamdani patterns from a collection of Jamdani motifs that we assembled, the newly formed motifs can mimic the appearance of the original designs. Users can input the skeleton of a desired pattern in terms of rough strokes and our system finalizes the input by generating the complete motif which follows the geometric structure of real Jamdani ones. To serve this purpose, we collected and preprocessed a dataset containing a large number of Jamdani motifs images from authentic sources via fieldwork and applied a state-of-the-art method called pix2pix on it.<br><br>
[ <a href="https://github.com/raihan-tanvir/generative-jamdani"; style="font-weight:bold">Our Jamdani Noksha Dataset published at ICCIT 2020</a> ] 
<br>
<br>
<br>
   <strong>Student collaborators:</strong> Shawon, Raihan, Shifa & Shusmoy.
<br>
<br>
<strong>Outcome:</strong>
<br>
<br>
<ul>
<li>Paper: ‘Jamdani Motif Generation using Conditional GAN’, ICCIT 2020.<br>
</li>
</ul>
</ul>
  </p>
<p align="center">
  <br>
    <img src="material/jam.png" widht = "400" height ="300">
</p>
  <br>
  <br>
  <br>
  <br>
  <a name="i2i"></a>
  <h2> Image to Image Attire Transfer (2020)</h2>
  <p class="lead"> [Ongoing] </p>
  <p class="lead">
  <ul>
    In this project, we are working on developing a technique for image-to-image attire transfer using Generative Adversarial Networks (GAN) and image processing methods that can transfer the clothing from a person’s image to another person’s image. Our system takes two images: (1) a full-length image of the user, and (2) an image of another person with a target clothing. Our method then produces a new image of the user with the targeted outfit while keeping the shape, pose, action, and identity of the user unchanged.<br>

<br>
   <strong>Student collaborators:</strong> Sanzam, Dipta, Nabil & Faisal.
<br>
<br>
<strong>Outcome:</strong>
<br>
<br>
<ul>
<li>Paper: ‘Image to Image Attaire Transfer for Virtual Trial Room’, ICCIT 2020.<br>
</li>
</ul>
</ul>
  </p>
<p align="center">
  <br>
    <img src="material/i2i.png" widht = "700" height ="180">
</p>
  <br>
  <br>
  <br>
  <br>
  <a name="bdsl"></a>
  <h2> Bangladeshi sign language detection using Deep Learning (2018)</h2>
  <p class="lead"> [Completed] </p>
  <p class="lead">
  <ul>
    In this project we are developing a technique to detect Bangladeshi Sign Language (BdSL) from images in real time. For this purpose, we develop a dataset – BdSLImset (Bangladeshi Sign Language Image Dataset) – to train our system.<br><br>
[ <a href="https://drive.google.com/drive/folders/1f9sLKK6D86tZH5celUQzUdZI0UtiRfGQ"; style="font-weight:bold">dataset published at ACCV 2020</a> ] <br><br>
[ <a href="https://github.com/imruljubair/bdslimset"; style="font-weight:bold">dataset published at ICIET 2018</a> ]
<br><br>
<br>
   <strong>Student collaborators:</strong> <a href="https://oishee30.github.io/OisheeBinteyHoque/">Oishee Hoque</a>, Md. Saiful Islam, Al-Farabi Akash and Alvin Paulson.
<br>
<br>
<strong>Outcome:</strong>
<br>
<br>
<ul>
<li>Paper: ‘BdSL36: A Dataset for Bangladeshi Sign Letters Recognition’, ACCV 2020.<br>
[ <a href="https://openaccess.thecvf.com/content/ACCV2020W/MLCSA/html/Hoque_BdSL36_A_Dataset_for_Bangladeshi_Sign_Letters_Recognition_ACCVW_2020_paper.html" ; style="font-weight:bold">pdf</a> ]</li>
<li>Paper: ‘Real Time Bangladeshi Sign Language Detection using Faster R-CNN’, ICIET 2018.<br>
[ <a href="https://arxiv.org/abs/1811.12813" ; style="font-weight:bold">arXiv</a> ] [ <a href="material/bdsl_slides.pdf"; style="font-weight:bold">slides</a> ]</li>
</ul>
</ul>
  </p>
<p align="center">
  <br>
    <img src="material/rcnn.png">
    <img src="material/bdsl.png">
  <br><br>
  <iframe width="400" height="255" src="https://www.youtube.com/embed/8NLwOpQCmW0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
  <br>
  <br>
  <br>
  <br>
  <br>

  <a name="cartoon"></a>
  <h2>Toon2real: Cartoon to Photorealistic image synthesis using GAN (2018)</h2>
  <p class="lead"> [Completed] </p>
  <p class="lead">
  <ul>
    This is a GAN based approach for cartoon to realistic image synthesis. Here, we are trying to translate cartoon-styled images into theri real-world scenes. In our work, we are using generative adversarial networks (GAN) and mainly focusing on <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf">CartoonGAN (2018)</a> and <a href= "https://arxiv.org/abs/1703.10593"> CycleGAN (2018)</a>.
<br>
<br>
   <strong>Student collaborators:</strong> Arefeen Sultan, Labiba Kanij, Nahidul Islam and Syed Hossain Khan.
<br>
<br>
<strong>Outcomes:</strong>
<br>
<br>
<ul>
<li>Paper: ‘Cartoon-to-real: An Approach to Translate Cartoon to Realistic Images using GAN’ (accepted as a student poster), International Conference on Innovation in Engineering and Technology (ICIET) 2018.<br>
[ <a href="https://arxiv.org/abs/1811.11796" ; style="font-weight:bold">arXiv</a> ] [ <a href="material/cartoon_poster.pdf"  ; style="font-weight:bold">poster</a> ]</li><br>
<li>Paper (submitted) to <a href="http://www.mldm.de/">MLDM 2019</a>.</li><br>
<li>1st Runner-up: Poster presentation at MINDSPARKS 2019.</li><br>
</ul>
<br>
</ul>
<p align="center">
<br>
<!--  <img src="material/t2r.png">
  <br>-->
  <img src="material/t2rall.png">
</p>
<br>
<br>
<br>
<br>
<br>

<a name="whymyface"></a>
<h2>WhyMyFace: <i>Wh</i><small>at it is in </small><i>y</i><small>our </small><i>M</i><small>ind is in </small><i>y</i><small>our </small><i>Face</i>! (2018)</h2>
<p class="lead"> [Ongoing] </p>
<p class="lead">
<ul>
  This project is aminig to alter facial expression of an user's picture in social media account according to his or her recent post. We are using GAN to transfer emotions from text to an image [Results are coming soon].
  <br>
<br>
  <strong>Student collaborators:</strong> Md. Amir Hamza, Md. Masud Rana, Ahnaf Tahseen and Fahim Ahsan Khan.
</ul>
</p>
<p align="center">
<br>
<img src="material/whymy.png">
</p>
<br>
<br>
<br>
<br>
<br>

<a name="icomaps"></a>
<h2>Icosahedral Maps for a Multiresolution Representation of Earth Data (2014 - 2016)</h2>
<p class="lead"> [Completed] </p>
<p class="lead">
<ul>
The project makes the following contributions:
<br>
<br>
<ul>
<li>We introduce <strong>"Icosahedral Maps"</strong>, an efficient mapping technique to capture the connectivity information for all cell-types in ICON’s soup structure and store it in a highly structured representation. This is an extension to the atlas of connectivity maps (ACM) data structure and represents the Earth’s surface as 2D hexagonal grids. We provide the necessary grid traversal scheme called – <strong>"Hexagonal Fan"</strong> – that suitably records the connectivity of all cell types in ICON in a common hexagonal representation.</li><br>
<li>We demonstrate, for ICON data, the decomposition to and reconstruction from different levels-of-detail using a function-based dyadic hexagonal wavelet scheme. Given the icosahedral maps, the wavelet filters associated with the <strong>hexagonal discrete wavelet transform</strong> are efficiently applied via 2D convolution, upsampling, and downsampling operations. The benefit of having such maps is that the same wavelet can be used for all cell-types.</li>
</ul>
<br>
Similar models to ICON – in terms of grid layout and structure – are the MPAS and the NICAM model. This makes the methods developed for ICON in this project almost directly applicable to MPAS and NICAM as well.
<br>
<br>
<strong>Outcomes:</strong>
<br>
<br>
<ul>
<li>Paper: "Icosahedral Maps for a Multiresolution Representation of Earth Data", VMV 2016.<br>
[ <a href="https://dl.acm.org/citation.cfm?id=3056928" ; style="font-weight:bold">link</a> ] [ <a href="papers/jubairVMV2016.pdf" ; style="font-weight:bold">paper</a> ]</li><br>
<li>Thesis: "Icosahedral Maps for a Multiresolution Representation of Earth Data", Department of Computer Science, University of Calgary, 2016.<br>
[ <a href="https://prism.ucalgary.ca/handle/11023/3527" ; style="font-weight:bold">link</a> ] [ <a href="http://visagg.cpsc.ucalgary.ca/sites/default/files/vmv%2Bdkrz.pdf" ; style="font-weight:bold">slides</a> ]</li>
</ul>

</ul>
</p>
<p align="center">
<br>
  <img src="material/thesis.png">   <img src="material/thesis2.png">
</p>
<br>
<br>
<br>
<br>
<br>

<a name="acm4icon"></a>
<h2>Implementing Atlas of Connectivity Maps for ICON Grid (2014)</h2>
<p class="lead"> [Completed] </p>
<p class="lead">
<ul>
  This project was a part of my MSc thesis. The goal of this project is to impelement <a href="https://doi.org/10.1016/j.cag.2013.09.003">the Atlas of Connectivity Maps</a> on <a href="https://www.dwd.de/EN/research/weatherforecasting/num_modelling/01_num_weather_prediction_modells/icon_description.html">ICON (Icosahedral Nonhydrostatic)</a> data. I developed a system that unfold the semiregular grids of the ICON model and map its connectivity information into 2D arrays corresponding to 2D regular pateches. I created a GUI to explore the ICON vertices and connectivity information interactively. The project was succefully completed as SciVis course project in fall 2014.
<br>
 <br>
  <strong>Outcome:</strong>
<br>
<br>
<ul>
<li>The project was later exteneded and multiresolution filters are applied on the 2D pateches to explore different levels-of-details (LoDs). The project was presented as a poster in CPSC Industrial Day 2015, University of Calgary.<br>
[ <a href="material/Implementing Atlas of Connectivity Maps for ICON Grid.pdf" ; style="font-weight:bold">project report</a> ]  [ <a href="material/CPSC 601 - Project Final Presentation.pdf" ; style="font-weight:bold">slides</a> ]  [ <a href="material/industrial_day_poster_jubair_(latest).pdf" ; style="font-weight:bold">poster</a> ]  [ <a href="https://github.com/imruljubair/SciVis-Course-Project-Fall-2014" ; style="font-weight:bold">code</a> ]</li>
</ul>
</ul>
</p>
<p align="center">
<br>
  <img src="material/screenshot.png">
</p>
<br>
<br>
<br>
<br>
<br>

<a name="glslicon"></a>
<h2>GLSL Impelementation of ICON Data Visualization (2015)</h2>
<p class="lead"> [Completed] </p>
<p class="lead">
<ul>
This is a part of my CPSC 691 Rendering course project. In this project, I visualized the triangle meshe from ICON (Icosahedral Nonhydrostatic) dataset using GLSL. In order to visualize, I used my favourite Parula colormap. I followed multipassing method to render triangle meshe with the edges.<br>
[<a href="https://github.com/imruljubair/Visualization-using-GLSL" ; style="font-weight:bold">code</a>]
</ul>
</p>
<p align="center">
<br>
<img src="material/glsl.png">    <img src="material/glsl2.png">
</p>
<br>
<br>
<p>|<a href="/project/project-page.html#";  style="font-weight:bold"> Jump to top </a>| or |<a href="/index.html#projects";  style="font-weight:bold"> Back to homepage </a>|</p>
</div>
</body>
</html>
